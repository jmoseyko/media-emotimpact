{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from ConvoAutoencoder import ConvoAutoencoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from data_utils import read_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start interactive tensorflow session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rejuvenate the trained variables\n",
    "reawakened = tf.train.import_meta_graph('ckpts/-13.meta')\n",
    "reawakened.restore(sess, tf.train.latest_checkpoint('ckpts/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating our autoencoder\n",
    "autoencoder = ConvoAutoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils_local08 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# importing the training images\n",
    "# extract the videos 9-13 to folders of frames --> could become a function in data_utils\n",
    "movie_num = 5\n",
    "new_import = 9\n",
    "for num in range(movie_num):\n",
    "    if new_import + num < 10:\n",
    "        pathin = os.path.join(\"data_movies\", \"MEDIAEVAL18_0{}.mp4\".format(new_import + num))\n",
    "        pathout = os.path.join(\"data_frames\", \"0{}\".format(new_import + num))\n",
    "    else:\n",
    "        pathin = os.path.join(\"data_movies\", \"MEDIAEVAL18_{}.mp4\".format(new_import + num))\n",
    "        pathout = os.path.join(\"data_frames\", \"{}\".format(new_import + num))\n",
    "    extractFrames_toFile(pathin, pathout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all of the frames in all of these folders, normalize, and compile them into a massive set of training data\n",
    "    # also a candidate for becoming a data_utils function\n",
    "longest_movie = 212\n",
    "for frame in range(longest_movie):\n",
    "    \n",
    "\n",
    "# save that training data into a local cpickle file for later use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code might be shorter to write: use opencv to read frames directly from the video file\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#X_input_test = np.zeros([7, 6298, 230400, 3])\n",
    "\n",
    "vidcap = cv2.VideoCapture('./data_movies/MEDIAEVAL18_07.mp4')\n",
    "num_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# eventualy num_frames will become the sum of all frames in all the videos\n",
    "X_input_test = np.zeros([7, num_frames, width*height, 3])\n",
    "\n",
    "success, image = vidcap.read()\n",
    "# count may need to be started outside of the loop that runs through all of the videos\n",
    "count = 0\n",
    "while success:\n",
    "    # flatten the image --> reshape it \n",
    "    new_img = np.reshape(image, [width*height, 3])\n",
    "    # add the image to the X_input_test array\n",
    "    # when dealing with all the movies, count will need to be creatively calculated \n",
    "    X_input_test[0, count, :, :] = new_img[:, :]\n",
    "    # read the next image from video file\n",
    "    success, image = vidcap.read()\n",
    "    count += 1\n",
    "    \n",
    "print(count)\n",
    "print(X_input_test)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the X_training data as a .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# send this data through the training step of the ConvoAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize one of the input/output frames of the ConvoAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the trained autoencoder --> the trained weights of the autoencoder and the model architecture will be \n",
    "    #sent into another folder, probably the LSTM folder "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

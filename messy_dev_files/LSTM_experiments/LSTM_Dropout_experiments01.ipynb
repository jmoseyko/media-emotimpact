{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# This version uses a model architecture with two LSTM layers and a dropout layer in between\n",
    "# again, just using part1 data for training and validation\n",
    "\n",
    "# Here I will be building out the architecture of the first classification LSTM\n",
    "# At each time step, this LSTM will take in a vector representing the extracted audio and visual features from Liris-ACCEDE\n",
    "# Its goal is to output whether or not the movie induces fear at each time step\n",
    "\n",
    "\n",
    "# First, import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# setting up the keras stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import LSTM\n",
    "# my custom data_utils file\n",
    "from data_utils_local08 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# uploading the X values\n",
    "X_input = load_Xinput(get_fc6_directory(7))\n",
    "print(X_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212,)\n"
     ]
    }
   ],
   "source": [
    "# uploading the Y values\n",
    "y_data_input = fear_oneHot(212, 'fear_annotations_part01/MEDIAEVAL18_7_Fear.txt')\n",
    "print(y_data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Uploading part01 of the local fc6 data\n",
    "\n",
    "timesteps = 212   # the number of seconds in movie 07 --> i will figure out how to programmatically get this value\n",
    "data_dim = 4096    # the number of output values from VGG16 layer fc6 --> switch to programmatic later\n",
    "num_movies = 4\n",
    "batch_size = 7\n",
    "num_epochs = 5\n",
    "validation_num = 3\n",
    "\n",
    "# set up the X_train_data master array\n",
    "X_train_data = np.zeros([num_movies, timesteps, data_dim]) #oooooh this array will have to be as long as the longest\n",
    "                                                            # movie and padded with zeros --> this won't cause problems\n",
    "                                                            # right?\n",
    "X_valid_data = np.zeros([validation_num, timesteps, data_dim])\n",
    "        \n",
    "# for each movie number between and including 7 and 13\n",
    "for num in range(num_movies):\n",
    "    # load the X_input data\n",
    "    X_input = load_Xinput(get_fc6_directory(7 + num))\n",
    "    # put this X_input data into the X_train_data array\n",
    "    X_train_data[num, :, :] = X_input\n",
    "print(X_train_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# loading X validation set\n",
    "X_valid_data = np.zeros([validation_num, timesteps, data_dim])\n",
    "\n",
    "for num in range(validation_num):\n",
    "    # load the X_input data\n",
    "    X_valid = load_Xinput(get_fc6_directory(7 + num_movies + num))\n",
    "    # put this X_input data into the X_train_data array\n",
    "    X_valid_data[num, :, :] = X_valid\n",
    "print(X_valid_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# uploading the y data\n",
    "\n",
    "# set up y_train_data master array\n",
    "Y_train_data = np.zeros([num_movies, timesteps])\n",
    "\n",
    "# for each movie number between and including 7 and 13\n",
    "for num in range(num_movies):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    #print(num)\n",
    "    path = os.path.join('fear_annotations_part01/MEDIAEVAL18_{}_Fear.txt'.format(7+num))\n",
    "    # create a one-hot vector\n",
    "    y_data = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    Y_train_data[num, :] = y_data\n",
    "print(Y_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# upload the Y validation set\n",
    "Y_valid_data = np.zeros([validation_num, timesteps])\n",
    "\n",
    "# for each movie number in validation set\n",
    "for num in range(validation_num):\n",
    "    # create the appropriate path to the fear annotation data\n",
    "    #print(num)\n",
    "    path = os.path.join('fear_annotations_part01/MEDIAEVAL18_{}_Fear.txt'.format(7+ num_movies + num))\n",
    "    # create a one-hot vector\n",
    "    y_valid = fear_oneHot(timesteps, path)\n",
    "    # add this one-hot vector to y_train_data\n",
    "    Y_valid_data[num, :] = y_valid\n",
    "print(Y_valid_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(212, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))\n",
    "# dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# another LSTM layer\n",
    "model.add(LSTM(212, return_sequences=True))\n",
    "\n",
    "# necessary flatten layer\n",
    "model.add(Flatten()) \n",
    "\n",
    "# add the final dense layer and then softmax\n",
    "model.add(Dense(212, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling LSTM model\n",
    "# note that Ng used an Adam optimizer and categorical cross-entropy loss\n",
    "# but this is a binary classification problem so I think the parameters below should suffice\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4 samples, validate on 3 samples\n",
      "Epoch 1/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.0507 - binary_accuracy: 0.8054 - val_loss: 2.0607 - val_binary_accuracy: 0.7689\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 0.9899 - binary_accuracy: 0.8054 - val_loss: 2.5496 - val_binary_accuracy: 0.7673\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 2.5300 - binary_accuracy: 0.8031 - val_loss: 3.0866 - val_binary_accuracy: 0.7689\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 3s 794ms/step - loss: 2.2222 - binary_accuracy: 0.8054 - val_loss: 3.2074 - val_binary_accuracy: 0.7689\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 3s 851ms/step - loss: 2.0226 - binary_accuracy: 0.8066 - val_loss: 3.4491 - val_binary_accuracy: 0.7689\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 1.9936 - binary_accuracy: 0.8054 - val_loss: 3.5082 - val_binary_accuracy: 0.7689\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 4s 975ms/step - loss: 2.5049 - binary_accuracy: 0.8054 - val_loss: 3.5848 - val_binary_accuracy: 0.7642\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.6354 - binary_accuracy: 0.8078 - val_loss: 3.5733 - val_binary_accuracy: 0.7657\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 3s 794ms/step - loss: 2.6264 - binary_accuracy: 0.8078 - val_loss: 3.5620 - val_binary_accuracy: 0.7689\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 3s 785ms/step - loss: 2.7023 - binary_accuracy: 0.8054 - val_loss: 3.6036 - val_binary_accuracy: 0.7673\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 3s 802ms/step - loss: 2.4029 - binary_accuracy: 0.8066 - val_loss: 3.5701 - val_binary_accuracy: 0.7673\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.5790 - binary_accuracy: 0.8078 - val_loss: 2.1760 - val_binary_accuracy: 0.7673\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 3s 809ms/step - loss: 1.4301 - binary_accuracy: 0.8066 - val_loss: 1.7835 - val_binary_accuracy: 0.7689\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 3s 783ms/step - loss: 1.3597 - binary_accuracy: 0.8054 - val_loss: 3.4232 - val_binary_accuracy: 0.7689\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 4s 1s/step - loss: 2.1492 - binary_accuracy: 0.8066 - val_loss: 2.1630 - val_binary_accuracy: 0.7689\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 4s 881ms/step - loss: 1.3227 - binary_accuracy: 0.8054 - val_loss: 1.3303 - val_binary_accuracy: 0.7689\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 1.0605 - binary_accuracy: 0.8054 - val_loss: 2.2040 - val_binary_accuracy: 0.7689\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 1.0275 - binary_accuracy: 0.8054 - val_loss: 1.5269 - val_binary_accuracy: 0.7689\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 3s 856ms/step - loss: 1.0387 - binary_accuracy: 0.8054 - val_loss: 1.7486 - val_binary_accuracy: 0.7689\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 4s 937ms/step - loss: 0.8750 - binary_accuracy: 0.8054 - val_loss: 1.5560 - val_binary_accuracy: 0.7689\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model.fit(X_train_data, Y_train_data, epochs = 20, validation_data=(X_valid_data, Y_valid_data))\n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction:\n",
      "[5.80215828e-06 4.54788733e-06 7.53379300e-06 5.51097401e-06\n",
      " 8.46636067e-06 4.16587000e-06 4.93033122e-06 7.82797997e-06\n",
      " 5.10781183e-06 5.04128957e-06 4.56491625e-06 9.48049001e-06\n",
      " 6.48030573e-06 5.32008380e-06 1.15500889e-05 8.18212447e-06\n",
      " 6.61045624e-06 6.81488382e-06 7.07102527e-06 8.40262237e-06\n",
      " 1.21017738e-05 5.32808008e-06 7.58328542e-06 7.86852434e-06\n",
      " 6.26041174e-06 4.04386219e-06 2.05821616e-05 6.65964080e-06\n",
      " 2.86260856e-05 1.84637629e-05 1.08862459e-05 2.60548477e-05\n",
      " 9.00484611e-06 8.30485624e-06 1.16883539e-05 1.18694952e-05\n",
      " 1.13861606e-05 5.97758801e-04 8.00490438e-04 9.67328378e-06\n",
      " 1.75866007e-05 2.22817471e-05 9.39848087e-06 1.50678961e-05\n",
      " 1.63513778e-05 9.91435627e-06 1.13243377e-05 3.24915381e-05\n",
      " 9.77735453e-06 2.03323489e-05 1.75254736e-05 1.30615981e-05\n",
      " 8.09948833e-04 6.45566499e-04 7.72805826e-04 6.33836025e-04\n",
      " 7.64632598e-04 8.44476977e-04 8.21812137e-04 8.42015841e-04\n",
      " 1.12248808e-05 1.16809661e-05 1.71042466e-05 9.41981943e-06\n",
      " 9.98779953e-01 9.98803973e-01 9.98834074e-01 9.98839080e-01\n",
      " 9.98715997e-01 9.99186456e-01 9.99287307e-01 9.99175370e-01\n",
      " 9.99491215e-01 9.99511838e-01 9.99273360e-01 9.99250591e-01\n",
      " 9.99340475e-01 9.99257267e-01 9.99170184e-01 9.99368250e-01\n",
      " 9.99257982e-01 9.99464691e-01 9.99417782e-01 9.99254048e-01\n",
      " 9.99481738e-01 9.99369323e-01 9.99246001e-01 9.99358356e-01\n",
      " 9.99263942e-01 9.99311566e-01 9.99316812e-01 9.99191344e-01\n",
      " 9.99365509e-01 9.99294281e-01 9.99380708e-01 9.98742282e-01\n",
      " 9.99225855e-01 9.99154329e-01 9.99120414e-01 9.98854756e-01\n",
      " 9.98733819e-01 9.98833477e-01 1.76317062e-05 8.26389987e-06\n",
      " 1.08187260e-05 9.98781383e-01 9.98674393e-01 9.98762488e-01\n",
      " 9.98764157e-01 9.98719931e-01 2.95270329e-05 1.38689329e-05\n",
      " 1.32257119e-05 8.39755921e-06 8.87508668e-06 1.55981124e-05\n",
      " 8.04343563e-06 3.45726767e-05 8.86108955e-06 2.12710656e-05\n",
      " 3.04750447e-05 1.94780514e-05 1.43612051e-05 2.14861357e-05\n",
      " 8.67216750e-06 2.23390871e-05 6.60853357e-06 4.05591618e-06\n",
      " 6.57759256e-06 9.99263227e-01 9.99262869e-01 9.99262273e-01\n",
      " 9.99264538e-01 9.99301195e-01 9.99090910e-01 9.99338567e-01\n",
      " 9.99307632e-01 9.99279559e-01 9.99324918e-01 9.99357402e-01\n",
      " 9.99353945e-01 9.99392748e-01 9.99211192e-01 9.99346435e-01\n",
      " 9.99362886e-01 9.99423146e-01 6.29150418e-06 4.93027028e-06\n",
      " 7.31007913e-06 5.14930161e-06 5.80701271e-06 6.53707593e-06\n",
      " 7.80127812e-06 9.37875666e-06 1.02595886e-05 5.31134856e-06\n",
      " 5.68024097e-06 6.10734696e-06 6.17751130e-06 6.23275810e-06\n",
      " 4.81156212e-06 8.51315690e-06 8.93149809e-06 5.73614216e-06\n",
      " 6.50554512e-06 5.21419952e-06 5.40390829e-06 6.49030699e-06\n",
      " 7.42228531e-06 7.46818159e-06 5.64171069e-06 6.78029255e-06\n",
      " 6.21621439e-06 9.84834514e-06 4.38709594e-06 4.86046702e-06\n",
      " 8.86166345e-06 4.72574447e-06 8.62467732e-06 6.19078128e-06\n",
      " 4.20730112e-06 4.69316501e-06 8.95214362e-06 6.73687600e-06\n",
      " 8.10548499e-06 9.22553772e-06 5.28622377e-06 5.31801879e-06\n",
      " 9.53178278e-06 7.09581627e-06 9.34559648e-06 7.99802365e-06\n",
      " 1.04552364e-05 1.91363069e-05 1.63565874e-05 1.31972365e-05\n",
      " 1.59480387e-05 6.15170256e-06 7.15101942e-06 7.21689230e-06\n",
      " 4.90019966e-06 7.86676082e-06 5.65994151e-06 5.99825262e-06\n",
      " 1.00857651e-05 4.83301119e-06 7.30536794e-06 9.56957228e-06\n",
      " 4.89718195e-06 6.58682620e-06 1.15005187e-05 3.33450453e-06]\n",
      "target:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "before 64:\n",
      "9.419819e-06\n",
      "64:\n",
      "0.998804\n",
      "rounded\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# trying to view the model output\n",
    "out = model.predict(X_train_data)\n",
    "print(\"model prediction:\")\n",
    "print(out[0])\n",
    "print(\"target:\")\n",
    "print(Y_train_data[0])\n",
    "\n",
    "print(\"before 64:\")\n",
    "print(out[0][63])\n",
    "print(\"64:\")\n",
    "print(out[0][65])\n",
    "\n",
    "print(\"rounded\")\n",
    "print(np.round(out)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try visualizing this model at some point?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

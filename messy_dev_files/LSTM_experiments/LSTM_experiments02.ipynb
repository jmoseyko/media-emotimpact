{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This version uses abstracted function to load X and Y training data into arrays of the right shape\n",
    "\n",
    "# Here I will be building out the architecture of the first classification LSTM\n",
    "# At each time step, this LSTM will take in a vector representing the extracted audio and visual features from Liris-ACCEDE\n",
    "# Its goal is to output whether or not the movie induces fear at each time step\n",
    "\n",
    "# First, import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting up the keras stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "# my custom data_utils file\n",
    "from data_utils_local05 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function for iterating through all of the files in a folder and loading them into input_data\n",
    "def load_Xinput(directory):\n",
    "    X_input = np.zeros([212, 4096]) # MAGIC NUMBERS\n",
    "    count = 0\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".txt\"):\n",
    "            input_data = np.loadtxt(os.path.join(directory, file), delimiter=',')\n",
    "            X_input[count, :] = np.asarray(input_data)[:]\n",
    "            #print(os.path.join(directory, filename))\n",
    "            count = count + 1\n",
    "            continue\n",
    "        else:\n",
    "            continue\n",
    "    return X_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# testing the function above\n",
    "X_input = load_Xinput('visual_features_part01/07/fc6/')\n",
    "print(X_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function for finding the correct fc6 folder\n",
    "def get_fc6_directory(movie_num):\n",
    "    return os.path.join(\"visual_features_part01\",\n",
    "                       \"{}\".format(movie_num), \n",
    "                       \"fc6\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual_features_part01/07/fc6\n"
     ]
    }
   ],
   "source": [
    "# for testing the function above\n",
    "print(get_fc6_directory(\"07\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -4.9211 ]\n",
      "  [  0.96259]\n",
      "  [ -3.5258 ]\n",
      "  ..., \n",
      "  [  0.40076]\n",
      "  [ -1.2796 ]\n",
      "  [ -0.35213]]\n",
      "\n",
      " [[ -5.0926 ]\n",
      "  [  0.81427]\n",
      "  [ -3.4552 ]\n",
      "  ..., \n",
      "  [  0.23162]\n",
      "  [ -1.2592 ]\n",
      "  [ -0.3475 ]]\n",
      "\n",
      " [[ -5.4391 ]\n",
      "  [ -8.3879 ]\n",
      "  [ -7.4676 ]\n",
      "  ..., \n",
      "  [ -9.9657 ]\n",
      "  [-10.339  ]\n",
      "  [  4.4491 ]]\n",
      "\n",
      " ..., \n",
      " [[ -8.2536 ]\n",
      "  [  2.4615 ]\n",
      "  [ -0.51632]\n",
      "  ..., \n",
      "  [  2.6969 ]\n",
      "  [ -2.1534 ]\n",
      "  [  6.2791 ]]\n",
      "\n",
      " [[ -8.3559 ]\n",
      "  [  2.6918 ]\n",
      "  [ -1.5177 ]\n",
      "  ..., \n",
      "  [  3.5107 ]\n",
      "  [ -4.4554 ]\n",
      "  [  6.395  ]]\n",
      "\n",
      " [[ -4.7936 ]\n",
      "  [  2.6032 ]\n",
      "  [ -3.5129 ]\n",
      "  ..., \n",
      "  [  1.774  ]\n",
      "  [  0.9897 ]\n",
      "  [  3.9134 ]]]\n"
     ]
    }
   ],
   "source": [
    "# testing the combination of the two functions\n",
    "print(load_Xinput(get_fc6_directory(\"07\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data01 shape:\n",
      "(4096, 1)\n",
      "X_input.shape\n",
      "(4096, 1)\n",
      "[[[-4.9211 ]\n",
      "  [ 0.96259]\n",
      "  [-3.5258 ]\n",
      "  ..., \n",
      "  [ 0.40076]\n",
      "  [-1.2796 ]\n",
      "  [-0.35213]]\n",
      "\n",
      " [[ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  ..., \n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]]\n",
      "\n",
      " [[ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  ..., \n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]]\n",
      "\n",
      " ..., \n",
      " [[ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  ..., \n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]]\n",
      "\n",
      " [[ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  ..., \n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]]\n",
      "\n",
      " [[ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  ..., \n",
      "  [ 0.     ]\n",
      "  [ 0.     ]\n",
      "  [ 0.     ]]]\n"
     ]
    }
   ],
   "source": [
    "# loading the X input values \n",
    "\n",
    "# create array of shape (210, 4096, 1) that will hold each second's worth of VGG16 data\n",
    "X_input = np.zeros([210, 4096, 1]) # MAGIC NUMBERS\n",
    "\n",
    "# iterate through the first axis length of this array and insert each second's worth of fc6 feature data\n",
    "# start counting seconds at 00001\n",
    "\n",
    "# testing function with just one second of input data:\n",
    "# I think this will fail because i need to treat the numbers as strings \n",
    "\n",
    "# uploading the X_values: fc6 feature data as input and figuring out its shape\n",
    "input_data01 = np.loadtxt('visual_features_part01/07/fc6/MEDIAEVAL18_07-00001_fc6.txt', delimiter=',')\n",
    "input_data02 = np.loadtxt('visual_features_part01/07/fc6/MEDIAEVAL18_07-00002_fc6.txt', delimiter=',')\n",
    "print(\"input_data01 shape:\")\n",
    "print(np.asarray(input_data01)[:, np.newaxis].shape)\n",
    "print(\"X_input.shape\")\n",
    "print(X_input[0,:,:].shape)\n",
    "X_input[0, :, :] = np.asarray(input_data01)[:, np.newaxis]\n",
    "print(X_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  64.  101.]\n",
      " [ 105.  109.]\n",
      " [ 129.  145.]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  1.  1.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# uploading the Y_values\n",
    "# the target data (y_values) will be a one-hot vector representing which seconds of movie induce fear\n",
    "\n",
    "# convert into function that takes following input args: movie_length, fear_annot_path\n",
    "# returns y_data_input\n",
    "\n",
    "# first access start and stop times for fear-inducing sequences\n",
    "y_data = np.loadtxt('fear_annotations_part01/MEDIAEVAL18_07_Fear.txt', skiprows=1)\n",
    "\n",
    "# now treat these as pairs of indices --> we want all the indices between each pair of numbers\n",
    "# create array of zeros --> the size will be the number of seconds in movie, in this case 210\n",
    "movie_length = 212 #MAGIC NUMBER ALERT! --> length of movie\n",
    "y_data_input = np.zeros((movie_length)) \n",
    "\n",
    "# for each element in first dimension of the y_data array\n",
    "for i in range(y_data.shape[0]):\n",
    "    # access the start time number and end time number\n",
    "    start = int(y_data[i][0])\n",
    "    end = int(y_data[i][1])\n",
    "    # set the elements between these indices in the zeros array to one\n",
    "    y_data_input[start] = 1 #maybe superfluous\n",
    "    y_data_input[end] = 1\n",
    "    y_data_input[start:end] = 1\n",
    "print(y_data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting up some key values\n",
    "timesteps = 212   # the number of seconds in movie 07 --> i will figure out how to programmatically get this value\n",
    "data_dim = 4096    # the number of output values from VGG16 layer fc6 --> switch to programmatic later\n",
    "# could data_dim be the number of features that have been extracted (for now visual features only) --> maybe too much\n",
    "\n",
    "# I have yet to figure this out\n",
    "X_train = input_data\n",
    "Y_train = y_data_input\n",
    "batch_size = 30 # very much arbitrary\n",
    "num_epochs = 20 # very much arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constructing a many-to-one LSTM model in keras --> inspiration: https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras\n",
    "# i will start by training a model on only the VGG16 fc6 layer output (that's just one feature)\n",
    "# should I eventually abstract this LSTM model? Create its own object file?\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(timesteps, data_dim), return_sequences=True))\n",
    "# going to add a softmax activation to this\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling LSTM model\n",
    "# note that Ng used an Adam optimizer and categorical cross-entropy loss\n",
    "# but this is a binary classification problem so I think the parameters below should suffice\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_2_input to have 3 dimensions, but got array with shape (4096, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-890a185f25e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# running the LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished training!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chloeloughridge/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_2_input to have 3 dimensions, but got array with shape (4096, 1)"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=num_epochs)\n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloeloughridge/anaconda/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# This version uses abstracted functions that actually work to load X and Y training data into arrays of the right shape\n",
    "# data successfully flows through LSTM connected to a flatten and dense layer\n",
    "\n",
    "# Here I will be building out the architecture of the first classification LSTM\n",
    "# At each time step, this LSTM will take in a vector representing the extracted audio and visual features from Liris-ACCEDE\n",
    "# Its goal is to output whether or not the movie induces fear at each time step\n",
    "\n",
    "# First, import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# setting up the keras stuff\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import LSTM\n",
    "# my custom data_utils file\n",
    "from data_utils_local06 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 4096)\n"
     ]
    }
   ],
   "source": [
    "# uploading the X values\n",
    "X_input = load_Xinput(get_fc6_directory(\"07\"))\n",
    "print(X_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212,)\n"
     ]
    }
   ],
   "source": [
    "# uploading the Y_values\n",
    "# the target data (y_values) will be a one-hot vector representing which seconds of movie induce fear\n",
    "\n",
    "# convert into function that takes following input args: movie_length, fear_annot_path\n",
    "# returns y_data_input\n",
    "\n",
    "# first access start and stop times for fear-inducing sequences\n",
    "y_data = np.loadtxt('fear_annotations_part01/MEDIAEVAL18_07_Fear.txt', skiprows=1)\n",
    "\n",
    "# now treat these as pairs of indices --> we want all the indices between each pair of numbers\n",
    "# create array of zeros --> the size will be the number of seconds in movie, in this case 210\n",
    "movie_length = 212 #MAGIC NUMBER ALERT! --> length of movie\n",
    "y_data_input = np.zeros((movie_length)) \n",
    "\n",
    "# for each element in first dimension of the y_data array\n",
    "for i in range(y_data.shape[0]):\n",
    "    # access the start time number and end time number\n",
    "    start = int(y_data[i][0])\n",
    "    end = int(y_data[i][1])\n",
    "    # set the elements between these indices in the zeros array to one\n",
    "    y_data_input[start] = 1 #maybe superfluous\n",
    "    y_data_input[end] = 1\n",
    "    y_data_input[start:end] = 1\n",
    "print(y_data_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 212, 4096)\n",
      "(1, 212)\n"
     ]
    }
   ],
   "source": [
    "# setting up some key values\n",
    "timesteps = 212   # the number of seconds in movie 07 --> i will figure out how to programmatically get this value\n",
    "data_dim = 4096    # the number of output values from VGG16 layer fc6 --> switch to programmatic later\n",
    "# could data_dim be the number of features that have been extracted (for now visual features only) --> maybe too much\n",
    "\n",
    "X_train_data = np.zeros([1, timesteps, data_dim])\n",
    "Y_train_data = np.zeros([1, timesteps])\n",
    "\n",
    "# I have yet to figure this out\n",
    "X_train_data[0, :, :] = X_input # the new axis will eventually become the batch size\n",
    "print(X_train_data.shape)\n",
    "Y_train_data[0, :] = y_data_input\n",
    "print(Y_train_data.shape)\n",
    "\n",
    "batch_size = 1 # very much arbitrary --> batch size relates to number of movies being put in\n",
    "num_epochs = 20 # very much arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# constructing a many-to-one LSTM model in keras --> inspiration: https://stackoverflow.com/questions/43034960/many-to-one-and-many-to-many-lstm-examples-in-keras\n",
    "# i will start by training a model on only the VGG16 fc6 layer output (that's just one feature)\n",
    "# should I eventually abstract this LSTM model? Create its own object file?\n",
    "model = Sequential()\n",
    "model.add(LSTM(212, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))\n",
    "# going to try adding a flatten layer in here\n",
    "model.add(Flatten()) # I got this from a github thing, but I still don't completely understand why it works\n",
    "# add the final dense layer and then softmax\n",
    "model.add(Dense(212, activation='softmax'))\n",
    "# going to add a softmax activation to this\n",
    "#model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compiling LSTM model\n",
    "# note that Ng used an Adam optimizer and categorical cross-entropy loss\n",
    "# but this is a binary classification problem so I think the parameters below should suffice\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.5827 - acc: 0.7170\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2857 - acc: 0.7170\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.4842 - acc: 0.7170\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.4182 - acc: 0.7217\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.2606 - acc: 0.7170\n",
      "finished training!\n"
     ]
    }
   ],
   "source": [
    "# running the LSTM model\n",
    "model.fit(X_train_data, Y_train_data, epochs = 5)\n",
    "print(\"finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 7.7531475e-04, 1.5394828e-02, 0.0000000e+00,\n",
       "        4.4442885e-24, 1.6717120e-01, 0.0000000e+00, 6.7480952e-02,\n",
       "        9.4659410e-32, 2.7323691e-25, 5.9435610e-07, 0.0000000e+00,\n",
       "        0.0000000e+00, 2.9394233e-24, 4.8555265e-08, 9.5977113e-02,\n",
       "        0.0000000e+00, 5.6363031e-04, 0.0000000e+00, 0.0000000e+00,\n",
       "        7.6922687e-38, 0.0000000e+00, 0.0000000e+00, 1.2317664e-35,\n",
       "        0.0000000e+00, 0.0000000e+00, 2.0579050e-08, 2.7556187e-24,\n",
       "        2.2021334e-07, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 3.5809626e-09, 8.3902174e-05, 0.0000000e+00,\n",
       "        0.0000000e+00, 3.6665253e-02, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 4.9532626e-36, 1.1621719e-27, 0.0000000e+00,\n",
       "        3.5570471e-36, 2.0196638e-24, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 4.0009212e-02, 6.1821770e-03, 3.8199580e-35,\n",
       "        6.1065905e-02, 0.0000000e+00, 1.7133225e-30, 1.9005951e-01,\n",
       "        9.7815180e-03, 2.9146475e-01, 3.2387703e-18, 1.5797228e-24,\n",
       "        6.9878693e-03, 1.0336071e-02, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to view the model output\n",
    "model.predict(X_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
